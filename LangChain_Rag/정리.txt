RAG
 - 기존의 대규모 언어 모델(LLM)을 확장하여, 주어진 컨텍스트나 질문에 대해 더욱 정확하고 풍부한 정보를 제공하는 방법
 - RAG 파이프라인은 기존의 언어 모델에 검색 기능을 추가하여, 주어진 질문이나 문제에 대해 더 정확하고 풍부한 정보를 기반으로 답변을 생성할 수 있게 해주는 것

RAG 파이프라인
    1. 데이터 로드
        - 데이터를 불러오는 단계
    2. 텍스트 분할
        - 불러온 데이터를 작은 크기의 단위로 분할하는 과정
    3. 인덱싱
        - 분할된 텍스트를 검색 가능한 형태로 만드는 단계
        - 텍스트 -> 임베딩으로 변환 -> 저장 -> 저장된 임베딩을 기반으로 유사성 검색을 수행
    4. 검색
        - 사용자의 질문이나 주어진 컨텍스트에 가장 관련된 정보를 찾아내는 과정
    5. 생성
        - 검색된 정보를 바탕으로 사용자의 질문에 답변을 생성

사용 이유
1. FAISS(Facebook AI Similarity Search) 사용 이유
    - 벡터의 압축된 표현을 사용하여 메모리 사용량을 최소화하면서도 검색 속도를 극대화하는 특징을 가졌음

2. MMR 검색 선택한 이유
    - MMR의 목적 : 검색 결과의 다양성을 증가시키는 것
    - 선택한 이유 : 여러가지 결과과 나오는 것을 확인하고 싶어서 